# load the data
import os

import numpy as np
import pandas as pd

# --------------------------------#
# constants
MIN_SD_DISPLAY = 0.5  # SD below this will be considered negligible

# --------------------------------#
# helper functions

# plt.rcParams["font.family"] = "DejaVu Sans"


def get_sort_key(type_name, sort_order):
    """Return sort key for consistent ordering. Used to make sure colors and tables are aligned."""
    try:
        return sort_order.index(type_name)
    except ValueError:
        return len(sort_order)  # Put unknown types at the end


def save_metrics_to_markdown(metrics, output_dir, df=None):
    md_content = """# Monte Carlo Simulation Metrics

## Overview
This document contains the Monte Carlo simulation metrics including n75, n50, n25 values with standard deviations and AUC scores.

"""

    # Add summary table if DataFrame is provided
    if df is not None:
        # Debug: print available columns and types
        print("DEBUG: DataFrame columns:", df.columns.tolist())
        print("DEBUG: Unique types:", df["type"].unique().tolist())
        print("DEBUG: Unique num_samples:", sorted(df["num_samples"].unique().tolist()))

        # Use all available types from the DataFrame
        type_order = sorted(df["type"].unique().tolist())

        # Create dynamic table header
        header_row = "| Cell Count | " + " | ".join(type_order) + " |"
        separator_row = (
            "|------------|"
            + "|".join(["-" * max(10, len(t)) for t in type_order])
            + "|"
        )

        md_content += """## Summary: Average Barcodes Generated by Cell Count

"""
        md_content += header_row + "\n"
        md_content += separator_row + "\n"

        # Define the cell count thresholds (orders of magnitude)
        cell_thresholds = [10, 100, 1000, 10000, 100000]

        for threshold in cell_thresholds:
            row_data = [f"{threshold}"]

            for barcode_type in type_order:
                # Filter data for this type and cell count
                type_data = df[
                    (df["type"] == barcode_type) & (df["num_samples"] == threshold)
                ]

                if not type_data.empty:
                    # Use unique_count as the column name for unique codes
                    mean_codes = type_data["unique_count"].mean()
                    sd_codes = type_data["unique_count"].std()

                    if not np.isnan(mean_codes):
                        formatted_value = format_mean_sd(mean_codes, sd_codes)
                        row_data.append(formatted_value)
                    else:
                        row_data.append("–")
                else:
                    row_data.append("–")

            md_content += "| " + " | ".join(row_data) + " |\n"

        md_content += "\n"

    md_content += """## Detailed Metrics

"""

    # Create header row dynamically from DataFrame columns
    headers = list(metrics.columns)
    header_row = "| " + " | ".join(headers) + " |"
    separator_row = "|" + "|".join(["------" for _ in headers]) + "|"

    md_content += header_row + "\n"
    md_content += separator_row + "\n"

    # Add data rows
    for _, row in metrics.iterrows():
        row_values = []
        for col in headers:
            value = row[col]
            # Format numeric values with appropriate precision
            if pd.isna(value):
                row_values.append("–")
            elif isinstance(value, (int, float)) and col != "length":  # noqa: UP038
                row_values.append(f"{value:.2f}")
            else:
                row_values.append(str(value))

        md_content += "| " + " | ".join(row_values) + " |\n"

    md_filename = os.path.join(output_dir, "monte_carlo_metrics.md")
    with open(md_filename, "w") as f:
        f.write(md_content)
    print(f"Metrics saved to {md_filename}")


# --------------------------------#
# simulation ll_50 code


def n_at_fraction(group, p=0.5):
    """
    Compute n_p (cells to reach fraction p unique) from Monte Carlo results.
    Interpolates on log-x scale using median fraction_unique_cells per num_samples.
    Returns:
        n_median, n_iqr, n_mean, n_sd
    """

    # Compute summary stats per num_samples
    stats = (
        group.groupby("num_samples")["fraction_unique_cells"]
        .agg(
            median="median",
            q25=lambda x: np.percentile(x, 25),
            q75=lambda x: np.percentile(x, 75),
            mean="mean",
            sd="std",
        )
        .reset_index()
    )
    stats["iqr"] = stats["q75"] - stats["q25"]

    x = stats["num_samples"].values
    y_median = stats["median"].values
    y_mean = stats["mean"].values
    y_sd = stats["sd"].values
    y_iqr = stats["iqr"].values

    # Enforce monotone decreasing on median
    y_median_smooth = np.minimum.accumulate(y_median)

    # Find first index where median <= p
    idx = np.where(y_median_smooth <= p)[0]
    if len(idx) == 0:
        return np.nan, np.nan, np.nan, np.nan
    i = idx[0]
    if i == 0:
        return x[0], y_iqr[0], x[0], y_sd[0]

    # Linear interpolation in log-x space
    x0, x1 = x[i - 1], x[i]
    y0, y1 = y_median_smooth[i - 1], y_median_smooth[i]

    if y0 == y1:
        return x1, y_iqr[i], x1, y_sd[i]

    lx0, lx1 = np.log(x0), np.log(x1)
    t = (p - y0) / (y1 - y0)
    ln_star = lx0 + t * (lx1 - lx0)
    n_median = float(np.exp(ln_star))  # Keep fractional for mathematical precision

    # For IQR: Find n-values where Q25 and Q75 curves reach fraction p
    # This gives us the range of cell numbers needed across the distribution
    y_q25_smooth = np.minimum.accumulate(stats["q25"].values)
    y_q75_smooth = np.minimum.accumulate(stats["q75"].values)

    # Find n where Q25 curve reaches p
    idx_q25 = np.where(y_q25_smooth <= p)[0]
    if len(idx_q25) == 0:
        n_q25 = np.nan
    else:
        i_q25 = idx_q25[0]
        if i_q25 == 0:
            n_q25 = x[0]
        else:
            x0_q25, x1_q25 = x[i_q25 - 1], x[i_q25]
            y0_q25, y1_q25 = y_q25_smooth[i_q25 - 1], y_q25_smooth[i_q25]
            if y0_q25 == y1_q25:
                n_q25 = x1_q25
            else:
                lx0_q25, lx1_q25 = np.log(x0_q25), np.log(x1_q25)
                t_q25 = (p - y0_q25) / (y1_q25 - y0_q25)
                n_q25 = float(np.exp(lx0_q25 + t_q25 * (lx1_q25 - lx0_q25)))

    # Find n where Q75 curve reaches p
    idx_q75 = np.where(y_q75_smooth <= p)[0]
    if len(idx_q75) == 0:
        n_q75 = np.nan
    else:
        i_q75 = idx_q75[0]
        if i_q75 == 0:
            n_q75 = x[0]
        else:
            x0_q75, x1_q75 = x[i_q75 - 1], x[i_q75]
            y0_q75, y1_q75 = y_q75_smooth[i_q75 - 1], y_q75_smooth[i_q75]
            if y0_q75 == y1_q75:
                n_q75 = x1_q75
            else:
                lx0_q75, lx1_q75 = np.log(x0_q75), np.log(x1_q75)
                t_q75 = (p - y0_q75) / (y1_q75 - y0_q75)
                n_q75 = float(np.exp(lx0_q75 + t_q75 * (lx1_q75 - lx0_q75)))

    # IQR is the difference between these n-values
    if not np.isnan(n_q75) and not np.isnan(n_q25):
        n_iqr = n_q75 - n_q25
    else:
        n_iqr = np.nan

    # For SD, we'll estimate it as IQR/1.35 (standard approximation)
    if not np.isnan(n_iqr):
        n_sd = n_iqr / 1.35  # IQR ≈ 1.35 * SD for normal distribution
    else:
        n_sd = np.nan

    # For n_mean, we need to do a separate interpolation using the mean curve
    y_mean_smooth = np.minimum.accumulate(y_mean)
    idx_mean = np.where(y_mean_smooth <= p)[0]
    if len(idx_mean) == 0:
        n_mean = np.nan
    else:
        i_mean = idx_mean[0]
        if i_mean == 0:
            n_mean = x[0]
        else:
            x0_mean, x1_mean = x[i_mean - 1], x[i_mean]
            y0_mean, y1_mean = y_mean_smooth[i_mean - 1], y_mean_smooth[i_mean]
            if y0_mean == y1_mean:
                n_mean = x1_mean
            else:
                lx0_mean, lx1_mean = np.log(x0_mean), np.log(x1_mean)
                t_mean = (p - y0_mean) / (y1_mean - y0_mean)
                ln_star_mean = lx0_mean + t_mean * (lx1_mean - lx0_mean)
                n_mean = float(
                    np.exp(ln_star_mean)
                )  # Keep fractional for mathematical precision

    return n_median, n_iqr, n_mean, n_sd


def auc_log(group, n_min=None, n_max=None):
    g = group.sort_values("num_samples")
    x = g["num_samples"].values
    y = g["mean_frac"].values
    lx = np.log(x)
    if n_min is not None or n_max is not None:
        # clip to [n_min, n_max] if provided
        mask = np.ones_like(x, dtype=bool)
        if n_min is not None:
            mask &= x >= n_min
        if n_max is not None:
            mask &= x <= n_max
        lx, y = lx[mask], y[mask]
    if len(lx) < 2:
        return np.nan
    # trapezoid on log-x
    area = np.trapz(y, lx)
    return area / (lx[-1] - lx[0])


def format_median_iqr(values, min_sd_display=MIN_SD_DISPLAY):
    """
    Compute median and interquartile range (IQR) for a list/array of values,
    and return a compact string for table display.
    """
    if values is None or len(values) == 0:
        return "–"

    try:
        arr = np.array(values, dtype=float)
        if np.isnan(arr).all():
            return "–"
    except (ValueError, TypeError):
        return "–"

    median = np.median(arr)
    q1 = np.percentile(arr, 25)
    q3 = np.percentile(arr, 75)
    iqr = q3 - q1

    # Format using type-safe UC formatting for table
    def _fmt(x):
        if x < 1e4:
            return f"{int(round(x))}"
        else:
            return f"{x:.1e}"

    return f"{_fmt(median)} ± {_fmt(iqr)}"


SUPERSCRIPTS = str.maketrans("0123456789-", "⁰¹²³⁴⁵⁶⁷⁸⁹⁻")


def format_power_of_ten(n: int) -> str:
    """
    Format a number as a power-of-ten string with Unicode superscripts.
    Examples:
      1e4   -> 10⁴
      5e5   -> 5×10⁵
    """
    if n >= 1e6:
        return "10" + str(int(6)).translate(SUPERSCRIPTS)
    elif n >= 5e5:
        return "5×10" + str(int(5)).translate(SUPERSCRIPTS)
    elif n >= 1e5:
        return "10" + str(int(5)).translate(SUPERSCRIPTS)
    elif n >= 5e4:
        return "5×10" + str(int(4)).translate(SUPERSCRIPTS)
    elif n >= 1e4:
        return "10" + str(int(4)).translate(SUPERSCRIPTS)
    else:
        return str(n)


def to_superscript(n: int) -> str:
    """Convert integer to Unicode superscript string."""
    return "".join(SUPERSCRIPTS.get(ch, ch) for ch in str(n))


def format_ll_value(n):
    """
    Format labeling limit (LL_p) values with smart rounding:
    - Small values (≤20): Keep exact integers (9 stays 9)
    - Medium values (21-999): Round to nearest 10 (176 → 180)
    - Large values (≥1000): Round to significant figures or scientific notation
    """
    # Handle None, NaN, or string inputs
    if n is None:
        return "–"

    # Convert to float if it's a string
    try:
        n = float(n)
    except (ValueError, TypeError):
        return "–"

    # Check for NaN
    if np.isnan(n):
        return "–"

    # Smart rounding based on magnitude
    if n <= 20:
        # Keep small values exact - every cell matters
        return f"{int(round(n))}"
    elif n < 100:
        # Round to nearest 5 for medium-small values (21-99)
        return f"{int(5 * round(n / 5))}"
    elif n < 1000:
        # Round to nearest 10 for medium values (100-999)
        return f"{int(10 * round(n / 10))}"
    elif n < 10000:
        # Round to nearest 50 for large values (1000-9999)
        return f"{int(50 * round(n / 50))}"
    elif n < 100000:
        # Use basic LaTeX notation - matplotlib mathtext is limited
        if n >= 1e6:
            return r"$10^6$"
        elif n >= 5e5:
            return r"$5$x$10^5$"
        elif n >= 1e5:
            return r"$10^5$"
        elif n >= 5e4:
            return r"$5$x$10^4$"
        elif n >= 1e4:
            return r"$10^4$"
        # else:
        # return format_power_of_ten(n)
    else:
        # Fallback to scientific notation for edge cases
        return f"{n:.1e}"


def format_mean_sd(mean, sd, min_sd_display=0.5, compact=False, compact_threshold=3):
    """
    Compact string representation of mean ± SD for tables.
    - mean, sd: numeric or convertible
    - min_sd_display: if SD < threshold, omit SD
    - compact: if True, use line breaks for very long values
    """
    # Validate mean
    try:
        mean = float(mean)
        if np.isnan(mean):
            return "–"
    except (ValueError, TypeError):
        return "–"

    # Validate SD
    sd_valid = True
    try:
        if sd is None or np.isnan(float(sd)) or float(sd) < min_sd_display:
            sd_valid = False
        else:
            sd = float(sd)
    except (ValueError, TypeError):
        sd_valid = False

    if sd_valid:
        mean_str = format_ll_value(mean)
        sd_str = format_ll_value(sd)

        if compact and (len(mean_str) + len(sd_str) >= compact_threshold):
            # Use line break for compact display - more aggressive threshold
            return f"{mean_str}\n±{sd_str}"
        else:
            return f"{mean_str} ± {sd_str}"
    else:
        return f"{format_ll_value(mean)}"


# ---
# plotting functions etc


def get_max_content_length(col_index, formatted_table_data):
    """Get the maximum character length for a column"""
    max_len = len(
        ["Type", "$LL_{75}$", "$LL_{50}$", "$LL_{25}$"][col_index]
    )  # Header length
    for row in formatted_table_data:
        max_len = max(max_len, len(str(row[col_index])))
    return max_len
